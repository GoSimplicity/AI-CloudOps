 # ==============================================
# AIOps平台生产环境配置文件
# ==============================================

# 应用基础配置
DEBUG=false
HOST=0.0.0.0
PORT=8080
LOG_LEVEL=INFO

# Prometheus配置 - 确保填写真实地址
PROMETHEUS_HOST=prometheus-server:9090
PROMETHEUS_TIMEOUT=30

# LLM模型配置 - 生产环境使用高质量模型
LLM_PROVIDER=openai
LLM_MODEL=Qwen/Qwen2.5-14B-Instruct
LLM_API_KEY=your-api-key-here
LLM_BASE_URL=https://api.siliconflow.cn/v1
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=4096

# 备用Ollama模型配置 - 作为备份
OLLAMA_MODEL=qwen2.5:14b
OLLAMA_BASE_URL=http://ollama-service:11434/v1

# 测试配置
SKIP_LLM_TESTS=false

# Kubernetes配置 - 生产环境使用in-cluster配置
K8S_IN_CLUSTER=true
K8S_NAMESPACE=default

# 根因分析配置
RCA_DEFAULT_TIME_RANGE=30
RCA_MAX_TIME_RANGE=1440
RCA_ANOMALY_THRESHOLD=0.7
RCA_CORRELATION_THRESHOLD=0.75

# 预测配置
PREDICTION_MODEL_PATH=/app/data/models/time_qps_auto_scaling_model.pkl
PREDICTION_SCALER_PATH=/app/data/models/time_qps_auto_scaling_scaler.pkl
PREDICTION_MAX_INSTANCES=20
PREDICTION_MIN_INSTANCES=1
PREDICTION_PROMETHEUS_QUERY='rate(nginx_ingress_controller_nginx_process_requests_total{service="ingress-nginx-controller-metrics"}[10m])'

# 通知配置 - 请确保填写真实的Webhook地址
FEISHU_WEBHOOK=https://open.feishu.cn/open-apis/bot/v2/hook/your-production-webhook-url
NOTIFICATION_ENABLED=true

# Tavily搜索配置
TAVILY_API_KEY=your-tavily-api-key-here
TAVILY_MAX_RESULTS=5

# 小助手配置
RAG_VECTOR_DB_PATH=/app/data/vector_db
RAG_COLLECTION_NAME=aiops-assistant-prod
RAG_KNOWLEDGE_BASE_PATH=/app/data/knowledge_base
RAG_CHUNK_SIZE=1000
RAG_CHUNK_OVERLAP=200
RAG_TOP_K=5
RAG_SIMILARITY_THRESHOLD=0.75
RAG_OPENAI_EMBEDDING_MODEL=BAAI/bge-m3
RAG_OLLAMA_EMBEDDING_MODEL=nomic-embed-text
RAG_MAX_CONTEXT_LENGTH=6000
RAG_TEMPERATURE=0.1