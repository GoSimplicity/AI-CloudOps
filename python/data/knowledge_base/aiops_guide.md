# AI-CloudOps å¹³å°å¿«é€Ÿå…¥é—¨æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç³»ç»Ÿè¦æ±‚

#### æœ€ä½è¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+, CentOS 8+) æˆ– macOS 10.15+
- **Python ç‰ˆæœ¬**: 3.11 æˆ–æ›´é«˜
- **å†…å­˜**: 4GB RAM
- **å­˜å‚¨**: 20GB å¯ç”¨ç£ç›˜ç©ºé—´
- **ç½‘ç»œ**: å¯è®¿é—®äº’è”ç½‘

#### æ¨èé…ç½®
- **CPU**: 4 æ ¸æˆ–æ›´å¤š
- **å†…å­˜**: 8GB RAM æˆ–æ›´å¤š
- **å­˜å‚¨**: 50GB SSD
- **Docker**: 20.10+ ç‰ˆæœ¬
- **Kubernetes**: 1.19+ ç‰ˆæœ¬ï¼ˆå¦‚éœ€ K8s åŠŸèƒ½ï¼‰

### ä¸€é”®å¯åŠ¨

#### ä½¿ç”¨ Docker Composeï¼ˆæ¨èï¼‰

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/GoSimplicity/AI-CloudOps.git
cd AI-CloudOps/python

# 2. é…ç½®ç¯å¢ƒå˜é‡
cp env.example env.production
# ç¼–è¾‘ env.production æ–‡ä»¶ï¼Œè®¾ç½®å¿…è¦çš„é…ç½®

# 3. å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d --build

# 4. ç­‰å¾…æœåŠ¡å¯åŠ¨å®Œæˆï¼ˆçº¦ 2-3 åˆ†é’Ÿï¼‰
docker-compose ps

# 5. éªŒè¯æœåŠ¡çŠ¶æ€
curl http://localhost:8080/api/v1/health
```

#### æœ¬åœ°å¼€å‘ç¯å¢ƒ

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv aiops-env
source aiops-env/bin/activate  # Linux/macOS
# æˆ– aiops-env\Scripts\activate  # Windows

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. é…ç½®ç¯å¢ƒå˜é‡
export ENV=development
export PROMETHEUS_HOST=127.0.0.1:9090
export LLM_PROVIDER=ollama

# 4. å¯åŠ¨åº”ç”¨
python app/main.py
```

### é…ç½®ç®¡ç†

#### ç¯å¢ƒå˜é‡é…ç½®ï¼ˆå¿…éœ€ï¼‰

åˆ›å»º `env.production` æ–‡ä»¶ï¼š

```bash
# ==================== ç¯å¢ƒé…ç½® ====================
ENV=production

# ==================== LLM é…ç½® ====================
# OpenAI å…¼å®¹ API é…ç½®
LLM_API_KEY=sk-your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1

# æˆ–è€…ä½¿ç”¨æœ¬åœ° Ollama
# LLM_PROVIDER=ollama
# OLLAMA_BASE_URL=http://127.0.0.1:11434

# ==================== ç›‘æ§é…ç½® ====================
PROMETHEUS_HOST=127.0.0.1:9090

# ==================== é€šçŸ¥é…ç½® ====================
# é£ä¹¦ Webhookï¼ˆå¯é€‰ï¼‰
FEISHU_WEBHOOK=https://open.feishu.cn/open-apis/bot/v2/hook/your-webhook

# ==================== æœç´¢é…ç½® ====================
# Tavily æœç´¢ APIï¼ˆå¯é€‰ï¼Œç”¨äºç½‘ç»œæœç´¢å¢å¼ºï¼‰
TAVILY_API_KEY=tvly-your-api-key-here

# ==================== Kubernetes é…ç½® ====================
# K8s é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
K8S_CONFIG_PATH=/path/to/kubeconfig
K8S_IN_CLUSTER=false
```

#### YAML é…ç½®æ–‡ä»¶

ç³»ç»Ÿä¼šæ ¹æ® `ENV` ç¯å¢ƒå˜é‡è‡ªåŠ¨é€‰æ‹©é…ç½®æ–‡ä»¶ï¼š
- `development`: ä½¿ç”¨ `config/config.yaml`
- `production`: ä½¿ç”¨ `config/config.production.yaml`

### éªŒè¯å®‰è£…

#### 1. å¥åº·æ£€æŸ¥

```bash
# ç³»ç»Ÿæ•´ä½“å¥åº·çŠ¶æ€
curl http://localhost:8080/api/v1/health

# é¢„æœŸå“åº”
{
  "status": "healthy",
  "timestamp": "2024-01-01T12:00:00Z",
  "services": {
    "prometheus": "healthy",
    "llm": "healthy",
    "vector_store": "healthy"
  }
}
```

#### 2. åŠŸèƒ½æµ‹è¯•

```bash
# æµ‹è¯•è´Ÿè½½é¢„æµ‹
curl http://localhost:8080/api/v1/predict

# æµ‹è¯•æ™ºèƒ½åŠ©æ‰‹
curl -X POST http://localhost:8080/api/v1/assistant/session

# æµ‹è¯•æ ¹å› åˆ†æï¼ˆéœ€è¦ Prometheus æ•°æ®ï¼‰
curl -X POST http://localhost:8080/api/v1/rca \
  -H "Content-Type: application/json" \
  -d '{
    "start_time": "2024-01-01T10:00:00Z",
    "end_time": "2024-01-01T11:00:00Z",
    "metrics": ["up"]
  }'
```

#### 3. Web ç•Œé¢

è®¿é—® API æ–‡æ¡£ç•Œé¢ï¼š
- **Swagger UI**: http://localhost:8080/docs
- **ReDoc**: http://localhost:8080/redoc

## ğŸ“š æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º

### 1. æ™ºèƒ½åŠ©æ‰‹ä½¿ç”¨

#### åˆ›å»ºä¼šè¯å¹¶æé—®

```bash
# åˆ›å»ºæ–°ä¼šè¯
SESSION_RESPONSE=$(curl -X POST http://localhost:8080/api/v1/assistant/session)
SESSION_ID=$(echo $SESSION_RESPONSE | jq -r '.session_id')

# æé—®
curl -X POST http://localhost:8080/api/v1/assistant/query \
  -H "Content-Type: application/json" \
  -d "{
    \"question\": \"å¦‚ä½•æŸ¥çœ‹ Kubernetes Pod çš„æ—¥å¿—ï¼Ÿ\",
    \"session_id\": \"$SESSION_ID\"
  }"
```

#### æ·»åŠ è‡ªå®šä¹‰çŸ¥è¯†

```bash
# 1. å°†æ–‡æ¡£æ·»åŠ åˆ°çŸ¥è¯†åº“ç›®å½•
echo "# è‡ªå®šä¹‰è¿ç»´æŒ‡å—
è¿™æ˜¯æˆ‘ä»¬å…¬å¸çš„ Kubernetes è¿ç»´æœ€ä½³å®è·µ...
" > data/knowledge_base/custom_guide.md

# 2. åˆ·æ–°çŸ¥è¯†åº“
curl -X POST http://localhost:8080/api/v1/assistant/refresh
```

### 2. è´Ÿè½½é¢„æµ‹ä½¿ç”¨

#### è·å–å½“å‰é¢„æµ‹

```bash
# åŸºäºå½“å‰ç³»ç»ŸçŠ¶æ€é¢„æµ‹
curl http://localhost:8080/api/v1/predict

# è‡ªå®šä¹‰ QPS é¢„æµ‹
curl -X POST http://localhost:8080/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{
    "current_qps": 150.0,
    "include_features": true
  }'
```

#### æŸ¥çœ‹è¶‹åŠ¿é¢„æµ‹

```bash
# é¢„æµ‹æœªæ¥ 24 å°æ—¶è´Ÿè½½
curl -X POST http://localhost:8080/api/v1/predict/trend \
  -H "Content-Type: application/json" \
  -d '{
    "hours_ahead": 24,
    "current_qps": 100.0
  }'
```

### 3. æ ¹å› åˆ†æä½¿ç”¨

#### æ‰§è¡Œ RCA åˆ†æ

```bash
# åˆ†ææœ€è¿‘ 1 å°æ—¶çš„å¼‚å¸¸
END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
START_TIME=$(date -u -d "1 hour ago" +"%Y-%m-%dT%H:%M:%SZ")

curl -X POST http://localhost:8080/api/v1/rca \
  -H "Content-Type: application/json" \
  -d "{
    \"start_time\": \"$START_TIME\",
    \"end_time\": \"$END_TIME\",
    \"metrics\": [
      \"container_cpu_usage_seconds_total\",
      \"container_memory_usage_bytes\"
    ]
  }"
```

### 4. K8s è‡ªåŠ¨ä¿®å¤ä½¿ç”¨

#### è¯Šæ–­é›†ç¾¤çŠ¶æ€

```bash
# è¯Šæ–­é»˜è®¤å‘½åç©ºé—´
curl -X POST http://localhost:8080/api/v1/autofix/diagnose \
  -H "Content-Type: application/json" \
  -d '{
    "namespace": "default"
  }'
```

#### è‡ªåŠ¨ä¿®å¤éƒ¨ç½²

```bash
# ä¿®å¤æœ‰é—®é¢˜çš„éƒ¨ç½²
curl -X POST http://localhost:8080/api/v1/autofix \
  -H "Content-Type: application/json" \
  -d '{
    "deployment": "nginx-deployment",
    "namespace": "default",
    "event": "Podå¯åŠ¨å¤±è´¥ï¼Œå¥åº·æ£€æŸ¥é…ç½®é”™è¯¯",
    "force": false
  }'
```

## ğŸ”§ å¸¸è§é…ç½®åœºæ™¯

### 1. çº¯æœ¬åœ°ç¯å¢ƒï¼ˆOllamaï¼‰

```bash
# å®‰è£… Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# ä¸‹è½½æ¨¡å‹
ollama pull qwen2.5:3b

# é…ç½®ç¯å¢ƒå˜é‡
export LLM_PROVIDER=ollama
export OLLAMA_BASE_URL=http://127.0.0.1:11434
export LLM_MODEL=qwen2.5:3b
```

### 2. äº‘ç«¯ APIï¼ˆOpenAI å…¼å®¹ï¼‰

```bash
# é…ç½®ç¯å¢ƒå˜é‡
export LLM_PROVIDER=openai
export LLM_API_KEY=sk-your-api-key
export LLM_BASE_URL=https://api.openai.com/v1
export LLM_MODEL=gpt-3.5-turbo
```

### 3. ç”Ÿäº§ç¯å¢ƒç›‘æ§é›†æˆ

```bash
# Prometheus é…ç½®
export PROMETHEUS_HOST=prometheus.monitoring.svc.cluster.local:9090

# Kubernetes é…ç½®
export K8S_IN_CLUSTER=true  # å¦‚æœåœ¨ K8s é›†ç¾¤å†…è¿è¡Œ
export K8S_CONFIG_PATH=/etc/kubernetes/admin.conf  # å¦‚æœåœ¨é›†ç¾¤å¤–
```

### 4. é€šçŸ¥ç³»ç»Ÿé…ç½®

```bash
# é£ä¹¦æœºå™¨äºº
export FEISHU_WEBHOOK=https://open.feishu.cn/open-apis/bot/v2/hook/xxx

# å¯ç”¨é€šçŸ¥
export NOTIFICATION_ENABLED=true
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è§£å†³

#### 1. LLM æœåŠ¡è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥ LLM æœåŠ¡çŠ¶æ€
curl http://localhost:8080/api/v1/health

# æµ‹è¯• Ollama è¿æ¥
curl http://127.0.0.1:11434/api/tags

# æµ‹è¯• OpenAI API
curl -H "Authorization: Bearer $LLM_API_KEY" \
     -H "Content-Type: application/json" \
     "$LLM_BASE_URL/models"
```

#### 2. Prometheus è¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥ Prometheus è¿æ¥
curl http://127.0.0.1:9090/-/healthy

# æµ‹è¯•æŸ¥è¯¢
curl "http://127.0.0.1:9090/api/v1/query?query=up"
```

#### 3. çŸ¥è¯†åº“åŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥çŸ¥è¯†åº“ç›®å½•
ls -la data/knowledge_base/

# æ‰‹åŠ¨åˆ·æ–°çŸ¥è¯†åº“
curl -X POST http://localhost:8080/api/v1/assistant/refresh

# æ£€æŸ¥å‘é‡æ•°æ®åº“
ls -la data/vector_db/
```

#### 4. å®¹å™¨å¯åŠ¨å¤±è´¥

```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker-compose logs aiops-backend

# æ£€æŸ¥èµ„æºä½¿ç”¨
docker stats

# é‡å¯æœåŠ¡
docker-compose restart aiops-backend
```

### æ—¥å¿—åˆ†æ

#### åº”ç”¨æ—¥å¿—ä½ç½®

```bash
# å®¹å™¨ç¯å¢ƒ
docker-compose logs -f aiops-backend

# æœ¬åœ°ç¯å¢ƒ
tail -f logs/app.log

# æŒ‰æ¨¡å—æŸ¥çœ‹æ—¥å¿—
grep "aiops.assistant" logs/app.log
grep "aiops.rca" logs/app.log
grep "aiops.predictor" logs/app.log
```

#### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è°ƒè¯•æ—¥å¿—
export LOG_LEVEL=DEBUG

# é‡å¯åº”ç”¨
python app/main.py
```

## ğŸ“– ä¸‹ä¸€æ­¥

### 1. æ·±å…¥äº†è§£åŠŸèƒ½

- **æ™ºèƒ½åŠ©æ‰‹**: é˜…è¯» [intelligent_assistant_guide.md](intelligent_assistant_guide.md)
- **è´Ÿè½½é¢„æµ‹**: é˜…è¯» [load_prediction_guide.md](load_prediction_guide.md)
- **æ ¹å› åˆ†æ**: é˜…è¯» [rca_analysis_guide.md](rca_analysis_guide.md)
- **K8s ä¿®å¤**: é˜…è¯» [k8s_autofix_guide.md](k8s_autofix_guide.md)

### 2. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

- é˜…è¯»å®Œæ•´éƒ¨ç½²æŒ‡å—
- é…ç½®ç›‘æ§å’Œå‘Šè­¦
- è®¾ç½®å¤‡ä»½å’Œæ¢å¤
- åˆ¶å®šè¿ç»´æµç¨‹

### 3. å®šåˆ¶å¼€å‘

- æŸ¥çœ‹ API æ–‡æ¡£
- äº†è§£æ‰©å±•æœºåˆ¶
- å¼€å‘è‡ªå®šä¹‰ Agent
- é›†æˆç°æœ‰ç³»ç»Ÿ

### 4. ç¤¾åŒºå‚ä¸

- æäº¤é—®é¢˜å’Œå»ºè®®
- åˆ†äº«ä½¿ç”¨ç»éªŒ
- è´¡çŒ®ä»£ç å’Œæ–‡æ¡£
- å‚ä¸æŠ€æœ¯è®¨è®º

## ğŸ“ è·å–å¸®åŠ©

### æŠ€æœ¯æ”¯æŒ

- **æ–‡æ¡£**: æŸ¥çœ‹å®Œæ•´æŠ€æœ¯æ–‡æ¡£
- **API æ–‡æ¡£**: http://localhost:8080/docs
- **GitHub Issues**: https://github.com/GoSimplicity/AI-CloudOps/issues
- **é‚®ä»¶æ”¯æŒ**: 13664854532@163.com

### å­¦ä¹ èµ„æº

- **ç¤ºä¾‹ä»£ç **: æŸ¥çœ‹ `examples/` ç›®å½•
- **æµ‹è¯•ç”¨ä¾‹**: æŸ¥çœ‹ `tests/` ç›®å½•
- **é…ç½®ç¤ºä¾‹**: æŸ¥çœ‹ `config/` ç›®å½•
- **è„šæœ¬å·¥å…·**: æŸ¥çœ‹ `scripts/` ç›®å½•

### ç¤¾åŒºäº¤æµ

- **é¡¹ç›®ä¸»é¡µ**: https://github.com/GoSimplicity/AI-CloudOps
- **æŠ€æœ¯åšå®¢**: å…³æ³¨é¡¹ç›®æ›´æ–°å’ŒæŠ€æœ¯åˆ†äº«
- **ç”¨æˆ·ç¾¤ç»„**: åŠ å…¥ç”¨æˆ·äº¤æµç¾¤

---

*æ¬¢è¿ä½¿ç”¨ AI-CloudOpsï¼å¦‚æœæ‚¨åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ã€‚*